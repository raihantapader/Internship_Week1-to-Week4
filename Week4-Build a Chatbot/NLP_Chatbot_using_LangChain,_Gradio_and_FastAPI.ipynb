{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai langchain langchain-openai python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NIoxSbUXrM3",
        "outputId": "ccf019a4-f8b3-4cee-c08c-f3abc9657bc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.9.18)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --force-reinstall langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KHgv6borYElu",
        "outputId": "f223fd4b-e347-4137-9f1e-57ed4ca97b78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain-openai)\n",
            "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai)\n",
            "  Using cached openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Using cached tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting packaging>=23.2 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pydantic>=2.7.4 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
            "  Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests>=2.26.0 (from tiktoken<1,>=0.7->langchain-openai)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
            "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Using cached langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "Using cached openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "Using cached tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: zstandard, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, packaging, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langchain-core, langchain-openai\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.25.0\n",
            "    Uninstalling zstandard-0.25.0:\n",
            "      Successfully uninstalled zstandard-0.25.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.9.18\n",
            "    Uninstalling regex-2025.9.18:\n",
            "      Successfully uninstalled regex-2025.9.18\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.3\n",
            "    Uninstalling orjson-3.11.3:\n",
            "      Successfully uninstalled orjson-3.11.3\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.11.0\n",
            "    Uninstalling jiter-0.11.0:\n",
            "      Successfully uninstalled jiter-0.11.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.1\n",
            "    Uninstalling typing-inspection-0.4.1:\n",
            "      Successfully uninstalled typing-inspection-0.4.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.31\n",
            "    Uninstalling langsmith-0.4.31:\n",
            "      Successfully uninstalled langsmith-0.4.31\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.76\n",
            "    Uninstalling langchain-core-0.3.76:\n",
            "      Successfully uninstalled langchain-core-0.3.76\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.3.33\n",
            "    Uninstalling langchain-openai-0.3.33:\n",
            "      Successfully uninstalled langchain-openai-0.3.33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.14.1 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.3 annotated-types-0.7.0 anyio-4.11.0 certifi-2025.8.3 charset_normalizer-3.4.3 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.11.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.76 langchain-openai-0.3.33 langsmith-0.4.31 openai-1.109.1 orjson-3.11.3 packaging-25.0 pydantic-2.11.9 pydantic-core-2.33.2 regex-2025.9.18 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.11.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "packaging"
                ]
              },
              "id": "ca4c9c5fd72744b1b5bd19ed4d6ad8b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "class ContextualChatSystem:\n",
        "    def __init__(self, api_key: str):\n",
        "        # Initialize GPT models (same for selection & generation)\n",
        "        self.selector_model = ChatOpenAI(\n",
        "            temperature=0.3,\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        self.generator_model = ChatOpenAI(\n",
        "            temperature=0.7,\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        # Selector prompt\n",
        "        self.selector_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are a context selection assistant.\n",
        "Available contexts:\n",
        "{contexts}\n",
        "\n",
        "User question: {question}\n",
        "\n",
        "Return ONLY the ID of the single most relevant context (e.g., 0, 1, 2).\n",
        "If none are relevant, return \"none\".\"\"\"\n",
        "        )\n",
        "\n",
        "        # Generator prompt (improved)\n",
        "        self.generator_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are an expert assistant answering strictly based on the provided context.\n",
        "\n",
        "Relevant context:\n",
        "{selected_context}\n",
        "\n",
        "User question:\n",
        "{question}\n",
        "\n",
        "Instructions:\n",
        "1. Answer the question clearly and concisely.\n",
        "2. Add 1‚Äì2 extra helpful facts from the context (if available).\n",
        "3. Always explain *which context* you used to answer.\n",
        "4. If the context does not contain the answer, reply:\n",
        "   \"I don't have that information in my knowledge base.\"\n",
        "5. Never invent facts.\n",
        "\n",
        "Format your response as:\n",
        "- ‚úÖ Answer\n",
        "- üìñ Context Used\n",
        "- ‚ÑπÔ∏è Extra Notes\"\"\"\n",
        "        )\n",
        "\n",
        "        # Chains\n",
        "        self.context_selector = (\n",
        "            {\"contexts\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "            | self.selector_prompt\n",
        "            | self.selector_model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        self.response_generator = (\n",
        "            {\"selected_context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "            | self.generator_prompt\n",
        "            | self.generator_model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "    def format_contexts(self, contexts):\n",
        "        \"\"\"Format contexts with IDs\"\"\"\n",
        "        return \"\\n\".join(f\"ID: {i}\\n{ctx}\" for i, ctx in enumerate(contexts))\n",
        "\n",
        "    def get_response(self, contexts, question):\n",
        "        \"\"\"Run context selection and response generation\"\"\"\n",
        "        formatted_contexts = self.format_contexts(contexts)\n",
        "\n",
        "        selected_context_id = self.context_selector.invoke({\n",
        "            \"contexts\": formatted_contexts,\n",
        "            \"question\": question\n",
        "        }).strip()\n",
        "\n",
        "        if selected_context_id.lower() == \"none\":\n",
        "            selected_context = \"No relevant context available\"\n",
        "        else:\n",
        "            try:\n",
        "                selected_context = contexts[int(selected_context_id)]\n",
        "            except (ValueError, IndexError):\n",
        "                selected_context = \"No relevant context available\"\n",
        "\n",
        "        response = self.response_generator.invoke({\n",
        "            \"selected_context\": selected_context,\n",
        "            \"question\": question\n",
        "        })\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    OPENAI_API_KEY = \"your_api_key_here\"\n",
        "\n",
        "    contexts = [\n",
        "        \"The capital of France is Paris. France is located in Western Europe and is known for its wine and cheese.\",\n",
        "        \"The Python programming language was created by Guido van Rossum and first released in 1991. It emphasizes code readability.\",\n",
        "        \"The human heart has four chambers: two atria and two ventricles. It pumps blood throughout the body.\"\n",
        "    ]\n",
        "\n",
        "    chat_system = ContextualChatSystem(api_key=\"Your api key\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nUser question (or 'quit' to exit): \")\n",
        "        if question.lower() in (\"quit\", \"exit\"):\n",
        "            break\n",
        "\n",
        "        response = chat_system.get_response(contexts, question)\n",
        "        print(\"\\nAI:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "k-y4EbrEd_39",
        "outputId": "5cf9094d-3c71-478c-8b52-1e961a85d102"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User question (or 'quit' to exit): Who is the running president of United Nation?\n",
            "\n",
            "AI: - ‚úÖ I don't have that information in my knowledge base.\n",
            "- üìñ No relevant context available\n",
            "\n",
            "User question (or 'quit' to exit): write something about dhaka city?\n",
            "\n",
            "AI: - Dhaka is the capital and largest city of Bangladesh.\n",
            "- üìñ Context Used: No relevant context available\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3273579533.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUser question (or 'quit' to exit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "# from fastapi import FastAPI # Removed FastAPI as not needed\n",
        "from datetime import datetime\n",
        "# import uvicorn # Removed uvicorn as not needed\n",
        "import os # Import os to access environment variables\n",
        "import time # Import the time module\n",
        "\n",
        "\n",
        "# Import your existing chat system\n",
        "# from your_chat_system_file import ContextualChatSystem  # remove this line\n",
        "\n",
        "# Copy the ContextualChatSystem class definition from cell k-y4EbrEd_39 here\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "class ContextualChatSystem:\n",
        "    def __init__(self, api_key: str):\n",
        "        # Initialize GPT models (same for selection & generation)\n",
        "        self.selector_model = ChatOpenAI(\n",
        "            temperature=0.3,\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        self.generator_model = ChatOpenAI(\n",
        "            temperature=0.7,\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        # Selector prompt\n",
        "        self.selector_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are a context selection assistant.\n",
        "Available contexts:\n",
        "{contexts}\n",
        "\n",
        "User question: {question}\n",
        "\n",
        "Return ONLY the ID of the single most relevant context (e.g., 0, 1, 2).\n",
        "If none are relevant, return \"none\".\"\"\"\n",
        "        )\n",
        "\n",
        "        # Generator prompt (improved)\n",
        "        self.generator_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are an expert assistant answering strictly based on the provided context.\n",
        "\n",
        "Relevant context:\n",
        "{selected_context}\n",
        "\n",
        "User question:\n",
        "{question}\n",
        "\n",
        "Instructions:\n",
        "1. Answer the question clearly and concisely.\n",
        "2. Add 1‚Äì2 extra helpful facts from the context (if available).\n",
        "3. Always explain *which context* you used to answer.\n",
        "4. If the context does not contain the answer, reply:\n",
        "   \"I don't have that information in my knowledge base.\"\n",
        "5. Never invent facts.\n",
        "\n",
        "Format your response as:\n",
        "- ‚úÖ Answer\n",
        "- üìñ Context Used\n",
        "- ‚ÑπÔ∏è Extra Notes\"\"\"\n",
        "        )\n",
        "\n",
        "        # Chains\n",
        "        self.context_selector = (\n",
        "            {\"contexts\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "            | self.selector_prompt\n",
        "            | self.selector_model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        self.response_generator = (\n",
        "            {\"selected_context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "            | self.generator_prompt\n",
        "            | self.generator_model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "    def format_contexts(self, contexts):\n",
        "        \"\"\"Format contexts with IDs\"\"\"\n",
        "        return \"\\n\".join(f\"ID: {i}\\n{ctx}\" for i, ctx in enumerate(contexts))\n",
        "\n",
        "    def get_response(self, contexts, question):\n",
        "        \"\"\"Run context selection and response generation\"\"\"\n",
        "        formatted_contexts = self.format_contexts(contexts)\n",
        "\n",
        "        selected_context_id = self.context_selector.invoke({\n",
        "            \"contexts\": formatted_contexts,\n",
        "            \"question\": question\n",
        "        }).strip()\n",
        "\n",
        "        if selected_context_id.lower() == \"none\":\n",
        "            selected_context = \"No relevant context available\"\n",
        "        else:\n",
        "            try:\n",
        "                selected_context = contexts[int(selected_context_id)]\n",
        "            except (ValueError, IndexError):\n",
        "                selected_context = \"No relevant context available\"\n",
        "\n",
        "        response = self.response_generator.invoke({\n",
        "            \"selected_context\": selected_context,\n",
        "            \"question\": question\n",
        "        })\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"your api key\"  # keep your key\n",
        "contexts = [\n",
        "    \"The capital of France is Paris. France is located in Western Europe and is known for its wine and cheese.\",\n",
        "    \"The Python programming language was created by Guido van Rossum and first released in 1991. It emphasizes code readability.\",\n",
        "    \"The human heart has four chambers: two atria and two ventricles. It pumps blood throughout the body.\"\n",
        "]\n",
        "\n",
        "chat_system = ContextualChatSystem(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# --- Gradio function ---\n",
        "chat_history = []\n",
        "\n",
        "def chat_gradio(user_message):\n",
        "    global chat_history\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Start timing AI response\n",
        "    start_time = time.time()\n",
        "    ai_response = chat_system.get_response(contexts, user_message)\n",
        "    end_time = time.time()\n",
        "\n",
        "    response_time = end_time - start_time\n",
        "\n",
        "    # Add messages to history\n",
        "    chat_history.append((f\"[{timestamp}] User: {user_message}\", f\"[{timestamp}] AI: {ai_response} (Response time: {response_time:.2f}s)\"))\n",
        "\n",
        "    # Flatten chat for Gradio display\n",
        "    display_history = []\n",
        "    for u, a in chat_history:\n",
        "        display_history.append(u)\n",
        "        display_history.append(a)\n",
        "\n",
        "    return \"\\n\\n\".join(display_history)\n",
        "\n",
        "# --- Gradio interface ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Contextual Chatbot\")\n",
        "    chatbot_output = gr.Textbox(label=\"Chat\", placeholder=\"Type your message here...\", lines=20, interactive=False)\n",
        "    user_input = gr.Textbox(label=\"Your Message\", placeholder=\"Type message here...\", lines=1)\n",
        "    send_btn = gr.Button(\"Send\")\n",
        "\n",
        "    send_btn.click(fn=chat_gradio, inputs=user_input, outputs=chatbot_output)\n",
        "    user_input.submit(fn=chat_gradio, inputs=user_input, outputs=chatbot_output)\n",
        "\n",
        "# Launch Gradio app directly\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "n8QZ98ljnUkM",
        "outputId": "8af84fda-78d2-4175-96d8-e483b4b67b0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e3b44aa284c7067a87.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e3b44aa284c7067a87.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rqs-7guoy5UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}